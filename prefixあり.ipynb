{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c3fb4ad455d24dc7a960cc3930c84157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6fe1f3dd11a4211969f986cdaf28456",
              "IPY_MODEL_44f0015f92ce401b96adf04425361262",
              "IPY_MODEL_f89950d98fff425cb7922c7186d878e1"
            ],
            "layout": "IPY_MODEL_acba202f8f6c40a9be6aac69e47c0a6a"
          }
        },
        "d6fe1f3dd11a4211969f986cdaf28456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9945c6a0d44b41de937b84a656116d38",
            "placeholder": "​",
            "style": "IPY_MODEL_259e90a70cd3403f97d9616b9357ef4f",
            "value": "Map: 100%"
          }
        },
        "44f0015f92ce401b96adf04425361262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1e70fce1da24772ad4e102736b7c497",
            "max": 681,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3abeb7da4ec740cf8ed8ea575b9b06e0",
            "value": 681
          }
        },
        "f89950d98fff425cb7922c7186d878e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25ee12013f59463abd06dc42cc05a56d",
            "placeholder": "​",
            "style": "IPY_MODEL_582963c02aa34dbb8dede059f43ec166",
            "value": " 681/681 [00:00&lt;00:00, 965.60 examples/s]"
          }
        },
        "acba202f8f6c40a9be6aac69e47c0a6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9945c6a0d44b41de937b84a656116d38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "259e90a70cd3403f97d9616b9357ef4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1e70fce1da24772ad4e102736b7c497": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3abeb7da4ec740cf8ed8ea575b9b06e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25ee12013f59463abd06dc42cc05a56d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "582963c02aa34dbb8dede059f43ec166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc441afe03f34ca5a44e98734343c712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_037c0a766e5743e8b8601b9956d34815",
              "IPY_MODEL_00db05b1544e41d689f071a6cd842671",
              "IPY_MODEL_e881837b99c340c0b2970f02134b4e54"
            ],
            "layout": "IPY_MODEL_0ab4506cbdbc49df8284cdff07db93df"
          }
        },
        "037c0a766e5743e8b8601b9956d34815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c54f6d74e0c040bda6ebdb5075ae91b1",
            "placeholder": "​",
            "style": "IPY_MODEL_5ea4cd724b234ed48db4b8f4ff9006bc",
            "value": "Map: 100%"
          }
        },
        "00db05b1544e41d689f071a6cd842671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f2b34321b22404ab0cc51dff6fa24eb",
            "max": 76,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d63febf402f14959827c82d5370b65cc",
            "value": 76
          }
        },
        "e881837b99c340c0b2970f02134b4e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87aceeed2e1e4e8ba1c201c555b27f42",
            "placeholder": "​",
            "style": "IPY_MODEL_50a99131839c44b9b8d0978f154e1146",
            "value": " 76/76 [00:00&lt;00:00, 857.15 examples/s]"
          }
        },
        "0ab4506cbdbc49df8284cdff07db93df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c54f6d74e0c040bda6ebdb5075ae91b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ea4cd724b234ed48db4b8f4ff9006bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f2b34321b22404ab0cc51dff6fa24eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d63febf402f14959827c82d5370b65cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87aceeed2e1e4e8ba1c201c555b27f42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50a99131839c44b9b8d0978f154e1146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IPxsCSfJlyb",
        "outputId": "e6f8f8f6-ce13-4521-f23d-81a233d75e96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 35692  100 35692    0     0   184k      0 --:--:-- --:--:-- --:--:--  185k\n"
          ]
        }
      ],
      "source": [
        "!curl -L \"https://gist.githubusercontent.com/Tosainu/47ed11f068f942026494/raw/cute_AA.txt\" -o cute_AA.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# train_kaomoji_byt5.py\n",
        "import os, random, math\n",
        "from typing import Dict, List\n",
        "import torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "import datasets\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
        "\n",
        "# ======== 設定（環境変数で上書きOK）========\n",
        "BASE_MODEL = os.environ.get(\"BASE_MODEL\", \"sonoisa/byt5-small-japanese\")\n",
        "RAW_FILE   = os.environ.get(\"RAW_FILE\", \"cute_AA.txt\")\n",
        "OUT_DIR    = os.environ.get(\"OUT_DIR\", \"./kaomoji_byt5_lora\")\n",
        "SEED       = int(os.environ.get(\"SEED\", 42))\n",
        "\n",
        "MAX_SOURCE_LEN = int(os.environ.get(\"MAX_SOURCE_LEN\", 32))\n",
        "MAX_TARGET_LEN = int(os.environ.get(\"MAX_TARGET_LEN\", 64))\n",
        "\n",
        "# LoRA（T5系の定番ターゲット）\n",
        "LORA_R = int(os.environ.get(\"LORA_R\", 16))\n",
        "LORA_ALPHA = int(os.environ.get(\"LORA_ALPHA\", 32))\n",
        "LORA_DROPOUT = float(os.environ.get(\"LORA_DROPOUT\", 0.05))\n",
        "\n",
        "EPOCHS = float(os.environ.get(\"EPOCHS\", 5))\n",
        "LR = float(os.environ.get(\"LR\", 2e-4))\n",
        "BATCH = int(os.environ.get(\"BATCH\", 32))\n",
        "GRAD_ACC = int(os.environ.get(\"GRAD_ACC\", 1))\n",
        "WARMUP_RATIO = float(os.environ.get(\"WARMUP_RATIO\", 0.05))\n",
        "\n",
        "import re\n",
        "from typing import Dict, List\n",
        "\n",
        "def load_pairs(path: str) -> List[Dict[str, str]]:\n",
        "    pairs = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for raw in f:\n",
        "            # 改行だけ消して、中身が空ならskip（前後の空白は保持したいのでstripはしない）\n",
        "            s = raw.rstrip(\"\\r\\n\")\n",
        "            if not s or s.strip() == \"\":\n",
        "                continue\n",
        "\n",
        "            # 1) タブ優先で分解（空カラムはそのまま残す）\n",
        "            cols_raw = s.split(\"\\t\")\n",
        "\n",
        "            # バリエーション対策：\n",
        "            # - 行末に余計なタブがあって空カラムが居る\n",
        "            # - 「顔文字」列が最後じゃない（まず無い想定だが保険）\n",
        "            # → 最後に出現する「顔文字」の直前までを有効データとみなす\n",
        "            last_kemoji_idx = None\n",
        "            for i in range(len(cols_raw) - 1, -1, -1):\n",
        "                if cols_raw[i].strip() == \"顔文字\":\n",
        "                    last_kemoji_idx = i\n",
        "                    break\n",
        "\n",
        "            if last_kemoji_idx is not None:\n",
        "                cols = cols_raw[:last_kemoji_idx]  # 「顔文字」以降を切り落とし\n",
        "            else:\n",
        "                # タブが無い/「顔文字」が無い行はフォールバック（空白ベース）\n",
        "                m = re.match(r\"^\\s*(.*?)\\s+(.+?)\\s*顔文字\\s*$\", s)\n",
        "                if m:\n",
        "                    left, right = m.group(1), m.group(2)\n",
        "                    left, right = left.strip(), right.strip()\n",
        "                    if left and right:\n",
        "                        pairs.append({\"input_text\": left, \"target_text\": right})\n",
        "                continue\n",
        "\n",
        "            # 有効カラムが最低2個（入力 + 顔文字）必要\n",
        "            if len(cols) < 2:\n",
        "                continue\n",
        "\n",
        "            # 入力は最初のカラム、顔文字は 2カラム目以降を結合（もし複数あればタブで復元）\n",
        "            left = cols[0].strip()\n",
        "            # 2列目以降をタブで繋ぎ直す（顔文字側にタブやスペースを含んでいても再現性を担保）\n",
        "            right = \"\\t\".join(cols[1:]).strip()\n",
        "\n",
        "            # 念のためゼロ幅・制御文字を除去（見た目崩れ対策）\n",
        "            # ただし通常の空白や記号は保持する\n",
        "            right = re.sub(r\"[\\u200B-\\u200D\\uFEFF]\", \"\", right)\n",
        "\n",
        "            if left and right:\n",
        "                pairs.append({\"input_text\": left, \"target_text\": right})\n",
        "\n",
        "    # 重複除去（順序保持）\n",
        "    uniq, seen = [], set()\n",
        "    for p in pairs:\n",
        "        key = (p[\"input_text\"], p[\"target_text\"])\n",
        "        if key not in seen:\n",
        "            uniq.append(p); seen.add(key)\n",
        "    return uniq\n",
        "\n",
        "\n",
        "def build_dataset(pairs: List[Dict[str,str]], seed: int = 42) -> DatasetDict:\n",
        "    random.Random(seed).shuffle(pairs)\n",
        "    n = len(pairs); n_train = int(n * 0.9)\n",
        "    return DatasetDict({\n",
        "        \"train\": Dataset.from_list(pairs[:n_train]),\n",
        "        \"validation\": Dataset.from_list(pairs[n_train:]),\n",
        "    })\n",
        "\n",
        "TASK_PREFIX = \"kaomoji: \"\n",
        "\n",
        "def preprocess(examples, tokenizer):\n",
        "    inputs = [TASK_PREFIX + s for s in examples[\"input_text\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=MAX_SOURCE_LEN,\n",
        "                             truncation=True, padding=\"max_length\")\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples[\"target_text\"],\n",
        "                           max_length=MAX_TARGET_LEN,\n",
        "                           truncation=True, padding=\"max_length\")\n",
        "    labels_ids = [[(-100 if t == tokenizer.pad_token_id else t) for t in seq]\n",
        "                  for seq in labels[\"input_ids\"]]\n",
        "    model_inputs[\"labels\"] = labels_ids\n",
        "    return model_inputs\n",
        "\n",
        "def metric_exact_match(eval_pred, tokenizer):\n",
        "    preds, labels = eval_pred\n",
        "\n",
        "    # -100 → pad に戻す（これは従来どおり）\n",
        "    labels = [[(t if t != -100 else tokenizer.pad_token_id) for t in seq] for seq in labels]\n",
        "\n",
        "    # ★ ByT5は offset(通常3)未満のIDは special 想定 → decode前に pad に逃がす\n",
        "    offset = getattr(tokenizer, \"offset\", 3)\n",
        "\n",
        "    def _safe(batch_ids):\n",
        "        safe = []\n",
        "        for seq in batch_ids:\n",
        "            # seq が tensor/ndarray の可能性もあるので list に\n",
        "            seq = list(map(int, seq))\n",
        "            safe.append([tid if tid >= offset else tokenizer.pad_token_id for tid in seq])\n",
        "        return safe\n",
        "\n",
        "    preds_safe  = _safe(preds)\n",
        "    labels_safe = _safe(labels)\n",
        "\n",
        "    pred_texts  = tokenizer.batch_decode(preds_safe,  skip_special_tokens=True)\n",
        "    label_texts = tokenizer.batch_decode(labels_safe, skip_special_tokens=True)\n",
        "\n",
        "    correct = sum(p.strip() == l.strip() for p, l in zip(pred_texts, label_texts))\n",
        "    return {\"exact_match\": correct / max(1, len(label_texts))}\n",
        "\n"
      ],
      "metadata": {
        "id": "DE7GP-N8JxHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "datasets.utils.logging.set_verbosity_error()\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# 1) データ\n",
        "pairs = load_pairs(RAW_FILE)\n",
        "if not pairs:\n",
        "    raise RuntimeError(\"データ0件。cute_AA.txtの場所/形式を確認してね。\")\n",
        "dsd = build_dataset(pairs, SEED)\n",
        "dsd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbyOxA16J6oY",
        "outputId": "d3cb05b0-23d5-414a-8407-9877645d2a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_text', 'target_text'],\n",
              "        num_rows: 681\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_text', 'target_text'],\n",
              "        num_rows: 76\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(100):\n",
        "    print(dsd[\"train\"][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Oa1hKUNSPlt",
        "outputId": "36cb9712-aa9e-4cea-f642-1bde69fa2a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_text': 'おふとん', 'target_text': '(:3[___]'}\n",
            "{'input_text': 'ずさぁ', 'target_text': \"⊂('ω`⊂ 三\"}\n",
            "{'input_text': 'ぱんち', 'target_text': '((⊂(╹◡╹๑∩)ｼｭｯｼｭｯ'}\n",
            "{'input_text': 'てへぺろ', 'target_text': 'てへぺろ！(*ゝωб)'}\n",
            "{'input_text': 'ふぇえ', 'target_text': '(*>_<*)ﾉ'}\n",
            "{'input_text': 'ねむい', 'target_text': '₍ᐢっ ̫-ᐢ₎'}\n",
            "{'input_text': 'なみだ', 'target_text': '(☍﹏⁰)'}\n",
            "{'input_text': 'おせんべい', 'target_text': 'ヾ(〄⌒ー⌒〄)ノ'}\n",
            "{'input_text': 'きゃぴ', 'target_text': '(´pゝω･)'}\n",
            "{'input_text': 'なみだ', 'target_text': '˚‧º·(˚ ˃̣̣̥᷄⌓˂̣̣̥᷅ )‧º·˚'}\n",
            "{'input_text': 'にこ', 'target_text': 'ε-ε-ヾ( o´∀)ﾂ'}\n",
            "{'input_text': 'ぶんぶん', 'target_text': 'ﾌﾞﾝ((>ω<｀*)(*´>ω<))ﾌﾞﾝ'}\n",
            "{'input_text': 'ぱーん', 'target_text': '( ‘д‘⊂彡☆))Д´)'}\n",
            "{'input_text': 'にこ', 'target_text': '(ﾟ▽ﾟ*)'}\n",
            "{'input_text': 'よし', 'target_text': '(๑˃̵ᴗ˂̵)و ﾖｼ!'}\n",
            "{'input_text': 'もうしわけねえ', 'target_text': \"ヽ('ω')ﾉ三ヽ('ω')ﾉ\"}\n",
            "{'input_text': 'ようせい', 'target_text': '(・ワ・)'}\n",
            "{'input_text': 'かーちゃん', 'target_text': \"Ｊ( 'ｰ`)し\"}\n",
            "{'input_text': 'ぎゅっ', 'target_text': '°+♡:.(っ>ω<c).:♡+°'}\n",
            "{'input_text': 'うーん', 'target_text': '(｡◕ˇｏˇ◕｡)'}\n",
            "{'input_text': 'にこ', 'target_text': '٩꒰｡•◡•｡꒱۶'}\n",
            "{'input_text': 'ぶいっ', 'target_text': \"v(*'-^*)ｂ\"}\n",
            "{'input_text': 'にこ', 'target_text': 'ヾ(･ω･*)ノ'}\n",
            "{'input_text': 'うわーん', 'target_text': 'ε二二二ε二二二(｡ﾟつД`)ﾟ｡ｳﾜｧｧ-----ﾝ!!!!'}\n",
            "{'input_text': 'じゅるり', 'target_text': 'ヽ(゜▽、゜)ノ'}\n",
            "{'input_text': 'ぽい', 'target_text': '[]⌒ ヽ(・ω・*)'}\n",
            "{'input_text': 'もぞもぞ', 'target_text': 'o(ﾟｰﾟo)｡｡｡｡3'}\n",
            "{'input_text': 'むー', 'target_text': '(๑•́ ₃ •̀๑)'}\n",
            "{'input_text': 'もきゅ', 'target_text': '(✘╹◡╹✘)'}\n",
            "{'input_text': 'もみもみ', 'target_text': 'ლ(╹◡╹ლ)'}\n",
            "{'input_text': 'しゅーてぃんぐ', 'target_text': '(´へωへ`*)'}\n",
            "{'input_text': 'あはは', 'target_text': '( ﾟ∀ﾟ)ｱﾊﾊ八八ﾉヽﾉヽﾉヽﾉ ＼ / ＼/ ＼'}\n",
            "{'input_text': 'のーとぱそこん', 'target_text': 'ﾉｰﾖﾊﾟﾖｺﾝ'}\n",
            "{'input_text': 'ねむい', 'target_text': '(´ぅω-｀)'}\n",
            "{'input_text': 'あつい', 'target_text': '(>﹏<｡Ξ｡>﹏<)'}\n",
            "{'input_text': 'なみ', 'target_text': '与本二上旦上二本与卉亠十廿卞广下广卞廿十亠卉'}\n",
            "{'input_text': 'あつい', 'target_text': 'ι(´Д｀υ)'}\n",
            "{'input_text': 'にやり', 'target_text': '(✧≖‿ゝ≖)'}\n",
            "{'input_text': 'もきゅ', 'target_text': \"(*'ω'*)\"}\n",
            "{'input_text': 'あひゃ', 'target_text': 'ｱﾋｬﾋｬﾋｬ(ﾟ∀ﾟ≡ﾟ∀ﾟ)ﾋｬﾋｬﾋｬ'}\n",
            "{'input_text': 'はい', 'target_text': '＼(( ･ิ ‿ ゝ･ิ ))/'}\n",
            "{'input_text': 'にやにや', 'target_text': '(⌒▽⌒)'}\n",
            "{'input_text': 'じー', 'target_text': '壁|ω・)'}\n",
            "{'input_text': 'なみだ', 'target_text': '。・°°・(＞_＜)・°°・。'}\n",
            "{'input_text': 'どごぉ', 'target_text': '－＝三∩(＞◡＜*)∩))Д´)どごぉ！'}\n",
            "{'input_text': 'ねる', 'target_text': '⊂⌒っ´ｰωｰ)っ.。o○'}\n",
            "{'input_text': 'しろめ', 'target_text': '( ꒪⌓꒪)'}\n",
            "{'input_text': 'てれ', 'target_text': '(*/∇＼*)'}\n",
            "{'input_text': 'ねる', 'target_text': '_(:0 」∠)_'}\n",
            "{'input_text': 'なでなで', 'target_text': 'ヾ(・ω・ )'}\n",
            "{'input_text': 'きゃぴ', 'target_text': '♡-(╹◡<✿)♪'}\n",
            "{'input_text': 'ねむい', 'target_text': '(´ぅω-｀)ﾈﾑｲ'}\n",
            "{'input_text': 'あたふた', 'target_text': 'ヽ(´･ω･｀ヽ)'}\n",
            "{'input_text': 'びろーん', 'target_text': '( ＞∀＜)σ＜ ´・ω・)ﾋﾞﾛｰﾝ'}\n",
            "{'input_text': 'ばんばん', 'target_text': '(੭ु⁾⁾＞_＜)੭ु⁾⁾'}\n",
            "{'input_text': 'しょぼーん', 'target_text': '(๑´╹‸╹`๑)'}\n",
            "{'input_text': 'きもっ', 'target_text': '三(((((´ω`；)'}\n",
            "{'input_text': 'もり', 'target_text': '┌(＾0＾)┘'}\n",
            "{'input_text': 'いそげ', 'target_text': 'ヽ(￣д￣;)ノ=3=3=3'}\n",
            "{'input_text': 'きゃぴ', 'target_text': '☆(ゝω･)v'}\n",
            "{'input_text': 'しょぼーん', 'target_text': 'il||li(つω-`。)il||li'}\n",
            "{'input_text': 'なでなで', 'target_text': 'ヾ(・ω・｀ )ﾅﾃﾞﾅﾃﾞ'}\n",
            "{'input_text': 'のし', 'target_text': 'ヽ^ｼ＞ω＜)ﾉｼ'}\n",
            "{'input_text': 'うるせえ', 'target_text': '⊂( ･∀･) 彡 =͟͟͞͞(●)`Д´)'}\n",
            "{'input_text': 'じたばた', 'target_text': 'ヾ(:3ﾉｼヾ)ﾉｼ'}\n",
            "{'input_text': 'にこ', 'target_text': '(✗╹◡╹)ﾉ'}\n",
            "{'input_text': 'ばんばん', 'target_text': '(ﾉｼ｀･ω･)ﾉｼ'}\n",
            "{'input_text': 'うーん', 'target_text': '(・ε・｀)'}\n",
            "{'input_text': 'ぷに', 'target_text': '( ＞∀＜)σ'}\n",
            "{'input_text': 'くしゃみ', 'target_text': \"( >д<).;':ﾍｯｸｼｮﾝ!\"}\n",
            "{'input_text': 'わいわい', 'target_text': 'ε( ε*＞ヮ＜)эわいわい'}\n",
            "{'input_text': 'あらまぁ', 'target_text': '(´・∀・｀ )ｱﾗﾏｧ'}\n",
            "{'input_text': 'よしよし', 'target_text': '(｡-∀-)ヾ(´∀｀*)'}\n",
            "{'input_text': 'あつい', 'target_text': 'ι(´Д｀υ)ｱｼﾞｨｰ'}\n",
            "{'input_text': 'えへへ', 'target_text': \"(๑'ᴗ'๑)\"}\n",
            "{'input_text': 'ねる', 'target_text': '_(・ω・｣ ∠)_'}\n",
            "{'input_text': 'じゃが', 'target_text': '(╮╯╭)'}\n",
            "{'input_text': 'ねむい', 'target_text': '(´･ωゞ)'}\n",
            "{'input_text': 'おっおっ', 'target_text': '(＾ω＾≡＾ω＾)おっおっ'}\n",
            "{'input_text': 'ばにたす', 'target_text': 'ᓀ‸ᓂ'}\n",
            "{'input_text': 'ぱぁあ', 'target_text': 'ヽ(*゜∀゜*)ノ'}\n",
            "{'input_text': 'てれ', 'target_text': '(。・ω・。)'}\n",
            "{'input_text': 'にこ', 'target_text': \"('ω'*)\"}\n",
            "{'input_text': 'くるくる', 'target_text': '‹‹⸜(*ˊᵕˋ* )⸝››‹‹⸜(    *)⸝››‹‹⸜( *ˊᵕˋ*)⸝››'}\n",
            "{'input_text': 'なみだ', 'target_text': '(ﾉω<､)'}\n",
            "{'input_text': 'てれ', 'target_text': '( //_// )'}\n",
            "{'input_text': 'げきおこ', 'target_text': '\\\\\\\\٩(๑`ȏ´๑)۶//'}\n",
            "{'input_text': 'おふとん', 'target_text': 'c(╹ω╹*c[___]'}\n",
            "{'input_text': 'ぷに', 'target_text': '(ㆀ˘･з･˘)σ)Д`)ｺｲﾂｩ'}\n",
            "{'input_text': 'ほし', 'target_text': '☆彡'}\n",
            "{'input_text': 'なみだ', 'target_text': '(ﾉω･､)'}\n",
            "{'input_text': 'てれ', 'target_text': '(*ﾉдﾉ)'}\n",
            "{'input_text': 'ひゅんひゅん', 'target_text': '=͟͟͞͞(๑╹ω╹三╹ω╹๑=͟͟͞͞)'}\n",
            "{'input_text': 'ぎゅっ', 'target_text': '((((⊃)☉ω☉(⊂)))))'}\n",
            "{'input_text': 'うー', 'target_text': '(」・ω・)」'}\n",
            "{'input_text': 'わふー', 'target_text': '(>ω<)'}\n",
            "{'input_text': 'びっくり', 'target_text': 'Σ((｡･ω･｡ )))'}\n",
            "{'input_text': 'よしよし', 'target_text': 'ヾ(╹◡╹๑)なでなでっ♪'}\n",
            "{'input_text': 'にこ', 'target_text': '☆ﾐ(o*･ω･)ﾉ'}\n",
            "{'input_text': 'もぐもぐ', 'target_text': '(´･ ～ ･`)'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sWxK8tu7Khbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) トークナイザー＆モデル（ByT5はSPM不要）\n",
        "print(f\"Loading base model: {BASE_MODEL}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True)\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu1S5EFIKTtJ",
        "outputId": "775addb9-87e3-4c56-f6c2-abaea96eb804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading base model: sonoisa/byt5-small-japanese\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) LoRA 注入（T5/ByT5の一般的なターゲット）\n",
        "lora_targets = [\"q\", \"k\", \"v\", \"o\", \"wi_0\", \"wi_1\", \"wo\"]\n",
        "lora = LoraConfig(\n",
        "    r=LORA_R, lora_alpha=LORA_ALPHA, lora_dropout=LORA_DROPOUT,\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM, bias=\"none\", target_modules=lora_targets,\n",
        ")\n",
        "model = get_peft_model(base_model, lora)\n",
        "model.print_trainable_parameters()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0T8EF5tKV47",
        "outputId": "5cefe1d7-6ec3-4937-e9a1-994d00d8ea4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 6,258,688 || all params: 305,896,448 || trainable%: 2.0460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) 前処理\n",
        "tokenized = dsd.map(lambda ex: preprocess(ex, tokenizer), batched=True,\n",
        "                    remove_columns=dsd[\"train\"].column_names)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "c3fb4ad455d24dc7a960cc3930c84157",
            "d6fe1f3dd11a4211969f986cdaf28456",
            "44f0015f92ce401b96adf04425361262",
            "f89950d98fff425cb7922c7186d878e1",
            "acba202f8f6c40a9be6aac69e47c0a6a",
            "9945c6a0d44b41de937b84a656116d38",
            "259e90a70cd3403f97d9616b9357ef4f",
            "c1e70fce1da24772ad4e102736b7c497",
            "3abeb7da4ec740cf8ed8ea575b9b06e0",
            "25ee12013f59463abd06dc42cc05a56d",
            "582963c02aa34dbb8dede059f43ec166",
            "fc441afe03f34ca5a44e98734343c712",
            "037c0a766e5743e8b8601b9956d34815",
            "00db05b1544e41d689f071a6cd842671",
            "e881837b99c340c0b2970f02134b4e54",
            "0ab4506cbdbc49df8284cdff07db93df",
            "c54f6d74e0c040bda6ebdb5075ae91b1",
            "5ea4cd724b234ed48db4b8f4ff9006bc",
            "9f2b34321b22404ab0cc51dff6fa24eb",
            "d63febf402f14959827c82d5370b65cc",
            "87aceeed2e1e4e8ba1c201c555b27f42",
            "50a99131839c44b9b8d0978f154e1146"
          ]
        },
        "id": "IjA0YgOKKZD0",
        "outputId": "2a49a90c-7b5b-43d8-edda-95431b542e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/681 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3fb4ad455d24dc7a960cc3930c84157"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4007: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/76 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc441afe03f34ca5a44e98734343c712"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Collator & 学習設定\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "bf16 = torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
        "fp16 = torch.cuda.is_available() and not bf16\n",
        "\n",
        "steps_per_epoch = math.ceil(len(tokenized[\"train\"]) / (BATCH * max(1, torch.cuda.device_count()) * max(1, GRAD_ACC)))\n",
        "from transformers import GenerationConfig\n",
        "\n",
        "gen_cfg = GenerationConfig(\n",
        "    max_new_tokens=24,\n",
        "    no_repeat_ngram_size=3,\n",
        "    encoder_no_repeat_ngram_size=3,\n",
        "    repetition_penalty=1.2,\n",
        "    num_beams=1,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ")\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=OUT_DIR,\n",
        "    per_device_train_batch_size=BATCH,\n",
        "    per_device_eval_batch_size=BATCH,\n",
        "    gradient_accumulation_steps=GRAD_ACC,\n",
        "    learning_rate=LR,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    warmup_ratio=WARMUP_RATIO,\n",
        "    logging_steps=max(1, steps_per_epoch // 5),\n",
        "\n",
        "    # ↓ここを evaluation_strategy から eval_strategy に変える\n",
        "    eval_strategy=\"epoch\",\n",
        "    generation_config=gen_cfg,   # ★評価時もこの条件で generate\n",
        "\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    predict_with_generate=True,\n",
        "    bf16=bf16, fp16=fp16,\n",
        "    dataloader_pin_memory=True,\n",
        "    report_to=\"none\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"exact_match\",\n",
        "    greater_is_better=True,\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model, args=args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=lambda x: metric_exact_match(x, tokenizer),\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhUvcIIfKbSQ",
        "outputId": "fe38ed82-a4d2-42e2-ee8f-e504073a47ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-509702583.py:44: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tokenizer type:\", type(tokenizer).__name__)\n",
        "print(\"len(tokenizer):\", len(tokenizer))\n",
        "print(\"model vocab_size:\", model.config.vocab_size)\n",
        "print(\"eos_token_id:\", tokenizer.eos_token_id, \"pad_token_id:\", tokenizer.pad_token_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee8h9YhbVOOS",
        "outputId": "72188518-078d-437b-b7cd-be90c100e893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer type: ByT5Tokenizer\n",
            "len(tokenizer): 384\n",
            "model vocab_size: 384\n",
            "eos_token_id: 1 pad_token_id: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) 学習\n",
        "trainer.train()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "bGgvyXDPKdMX",
        "outputId": "12a3b92b-6bb6-475f-bb56-34ef75106a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [110/110 01:52, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.282400</td>\n",
              "      <td>2.949673</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.580600</td>\n",
              "      <td>2.212036</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.143000</td>\n",
              "      <td>1.988311</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.087300</td>\n",
              "      <td>1.909775</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.965000</td>\n",
              "      <td>1.888562</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=110, training_loss=2.544600491090254, metrics={'train_runtime': 112.9098, 'train_samples_per_second': 30.157, 'train_steps_per_second': 0.974, 'total_flos': 199613074268160.0, 'train_loss': 2.544600491090254, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) ベスト保存（LoRAアダプタ＆tokenizer）\n",
        "trainer.model.save_pretrained(os.path.join(OUT_DIR, \"adapter\"))\n",
        "tokenizer.save_pretrained(OUT_DIR)\n",
        "\n",
        "# 8) LoRAをベースにマージ（単一モデルとして配布・推論用）\n",
        "print(\"Merging LoRA into base weights...\")\n",
        "merged = trainer.model.merge_and_unload() if isinstance(trainer.model, PeftModel) else trainer.model\n",
        "merged.save_pretrained(os.path.join(OUT_DIR, \"merged\"))\n",
        "print(\"Done. Saved under:\", OUT_DIR)"
      ],
      "metadata": {
        "id": "kEbYET2QKeSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e4360d-27e2-4f15-acad-9bc90712be00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merging LoRA into base weights...\n",
            "Done. Saved under: ./kaomoji_byt5_lora\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LogitsProcessor\n",
        "import torch\n",
        "\n",
        "class BanHiraganaAllowKatakana(LogitsProcessor):\n",
        "    \"\"\"\n",
        "    ByT5用：ひらがな (U+3040–309F) を禁止、カタカナ (U+30A0–30FF) は許可。\n",
        "    UTF-8パターン:\n",
        "      ひらがな:  E3 81 80..BF,  E3 82 80..9F\n",
        "      カタカナ:  E3 82 A0..BF,  E3 83 80..BF\n",
        "    \"\"\"\n",
        "    def __init__(self, tokenizer, vocab_size=None):\n",
        "        self.offset = getattr(tokenizer, \"offset\", 3)\n",
        "        self.vocab_size = vocab_size if vocab_size is not None else getattr(tokenizer, \"vocab_size\", 384)\n",
        "\n",
        "        # 便利: byte値→token_id の写像（specialは除外、0..255のみ有効）\n",
        "        self.byte_to_tid = {}\n",
        "        for b in range(256):\n",
        "            tid = b + self.offset\n",
        "            if 0 <= tid < self.vocab_size:\n",
        "                self.byte_to_tid[b] = tid\n",
        "\n",
        "    def _last_valid_bytes(self, ids_row, k=2):\n",
        "        \"\"\"末尾から special を除外しつつ、直近の実バイト(0..255)を最大k個返す（順番は古→新）。\"\"\"\n",
        "        out = []\n",
        "        for t in reversed(ids_row.tolist()):\n",
        "            b = int(t) - self.offset\n",
        "            if 0 <= b <= 255:\n",
        "                out.append(b)\n",
        "                if len(out) >= k:\n",
        "                    break\n",
        "        return list(reversed(out))\n",
        "\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
        "        batch_size = input_ids.size(0)\n",
        "        for i in range(batch_size):\n",
        "            ctx = self._last_valid_bytes(input_ids[i], k=2)\n",
        "\n",
        "            banned_bytes = set()\n",
        "\n",
        "            if not ctx:\n",
        "                # 先頭バイト段階：E3自体は許可（この時点で弾くとカタカナも死ぬ）\n",
        "                pass\n",
        "\n",
        "            elif len(ctx) == 1:\n",
        "                b1 = ctx[0]\n",
        "                if b1 == 0xE3:\n",
        "                    # 2バイト目に 0x81 が来たら \"E3 81 ...\" → ひらがな確定なので禁止\n",
        "                    # 0x82 は次で分岐（0x80..9F=ひらがな, 0xA0..=カタカナ）なので許可\n",
        "                    if 0x81 in self.byte_to_tid:\n",
        "                        banned_bytes.add(0x81)\n",
        "\n",
        "            else:  # len(ctx) >= 2\n",
        "                b1, b2 = ctx[-2], ctx[-1]\n",
        "                if b1 == 0xE3 and b2 == 0x81:\n",
        "                    # E3 81 xx は全部ひらがな → 3バイト目 全禁止\n",
        "                    banned_bytes.update(range(0x80, 0xC0))  # 0x80..0xBF\n",
        "                elif b1 == 0xE3 and b2 == 0x82:\n",
        "                    # E3 82 80..9F はひらがな、A0..BF はカタカナ → 下限だけ禁止\n",
        "                    banned_bytes.update(range(0x80, 0xA0))  # 0x80..0x9F\n",
        "\n",
        "            if banned_bytes:\n",
        "                banned_tids = [self.byte_to_tid[b] for b in banned_bytes if b in self.byte_to_tid]\n",
        "                if banned_tids:\n",
        "                    scores[i, banned_tids] = float(\"-inf\")\n",
        "\n",
        "        return scores\n"
      ],
      "metadata": {
        "id": "5EnE9nVpuKqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# infer_kaomoji.py\n",
        "import os, torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "MODEL_DIR = os.environ.get(\"MODEL_DIR\", \"./kaomoji_byt5_lora/merged\")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=True)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_DIR).to(DEVICE)\n",
        "model.eval()\n",
        "logits_processors = [BanHiraganaKanjiBytes(tokenizer)]\n",
        "def predict(s: str) -> str:\n",
        "    # 入力に接頭辞を付与\n",
        "    x = tokenizer(TASK_PREFIX + s, return_tensors=\"pt\").to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        y = model.generate(\n",
        "            **x,\n",
        "            # 反復よけ設定（短文×顔文字向け）\n",
        "            max_new_tokens=24,\n",
        "            no_repeat_ngram_size=3,\n",
        "            encoder_no_repeat_ngram_size=3,\n",
        "            repetition_penalty=1.2,\n",
        "            num_beams=1,  # ビーム大は反復誘発しがち。ここは1でOK\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            early_stopping=True,\n",
        "            logits_processor=logits_processors,  # ★ここ\n",
        "        )\n",
        "    return tokenizer.decode(\n",
        "        y[0], skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        "    ).strip()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    for text in [\"あせ\", \"おこ\", \"うえーん\", \"いえーい\", \"がおー\"]:\n",
        "        print(text, \"->\", predict(text))\n"
      ],
      "metadata": {
        "id": "rYow5h_9PNfA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43fb02ff-9a08-49f8-aa68-f95b8d43d887"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "あせ -> … ☆ ♪\n",
            "おこ -> omeji... … ₎ ■▽\n",
            "うえーん -> ☆ ♪ ○ ■▽△\n",
            "いえーい -> _ ○ ■ ☆ ♡︎♪\n",
            "がおー -> omaji.: … ☆\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "orW4LhsPSC0Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}